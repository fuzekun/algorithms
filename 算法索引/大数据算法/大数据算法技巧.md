# 大数据算法技巧

1. hash函数可以把数据流按照种类均匀分类
2. 布隆过滤器用于集合的建立与查询，并可以节省大量空间
3. 一致性hash解决数据服务器的负载管理问题
4. 利用并查集结构做岛问题的并行计算
5. 位图解决某一范围上数字的出现情况，并可以节省大量空间
6. 利用分段统计思想、并进一步节省大量空间
7. 利用堆、外排序处理国歌单元的结果并且合并





## 技巧7举例

问题：100亿

![image-20220507150450433](https://gitee.com/tobewin3/picgo-home/raw/master/imgs/image-20220507150450433.png)



**首先考虑如何计数，也就是每一个url出现了多少次呢？**

1. 使用布隆过滤。（还没学）
2. 使用hash函数进行分流，将相同的hash值取模的url放到同一个文件中。
   1. 每一个url对应一个字符串hash。
   2. 这个字符串hash对一个数取模
   3. 那么这样同一种url就会进入一个文件中去。

**第二个问题,统计前100:**

1. 先把100亿条数据使用hash函数进行分流。
2. 然后对于每一个文件
   1. 进行一个hashMap的统计，url作为key, 词频作为value。
   2. 按照value进行排序。
   3. 把排好的内容放入磁盘中。
3. 最后进行统计。
   1. 首先进行建堆：从每个文件中读取第一条数据，然后将他们从文件中**删除**，把<文件名，文件数据> 存入大根堆中。
   2. 然后在cnt < N **且 堆不空**时：
      1. 堆顶加入答案。
      2. 堆顶对应的文件，如果不空，读取第一条数据加入堆，并且**删除**第一条数据。
   3. 知道满足统计了N条，或者堆为空(没有这么多种的url)的时候返回统计的答案。



**这里记录下一些其他问题**

1. 文件统计之后是放在磁盘中，还是存储在内存中呢？
   - 放在磁盘中，因为建立就算统计完成之后，url的数量依旧很多，可能到达10亿条。
2. 如何更少的读取磁盘？
   - 败者树(还没学)









